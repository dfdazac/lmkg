import asyncio
from typing import Any, Callable, Optional

from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent, ToolNode
import pydantic

from .tools import AnswerStoreTool, GraphDBTool
from .utils import build_task_input


class LMKGAgent:
    """
    An agent designed to interact with a pre-trained language model and a
    knowledge graph database (GraphDB). It facilitates the generation of
    text-based responses using a language model and integrates with tools to
    process and retrieve information from a knowledge graph.

    Args:
        functions (list[str]): A list of function names to use with the graph database,
            or the string "all" to use all available functions.
        graphdb_endpoint (str): The URL endpoint for accessing the graph database.
        timeout (int, optional): The maximum time in seconds to allow for agent execution.
        recursion_limit (int, optional): The maximum recursion depth for the agent's execution.
    """
    def __init__(self,
                 functions: list[str],
                 graphdb_endpoint: str,
                 answer_parser: Callable[[str], tuple[Any, set[str]]] = None,
                 timeout: int = None,
                 recursion_limit: int = None):
        self.graphdb_endpoint = graphdb_endpoint
        self.graphdb = GraphDBTool(graphdb_endpoint, functions)
        self.answer_store = AnswerStoreTool(self.graphdb, answer_parser)
        tool_list = self.graphdb.tools + self.answer_store.tools

        model = ChatOpenAI(
            model="nf-gpt-4o-mini",
            temperature=0,
            max_retries=2,
            base_url="https://ai-research-proxy.azurewebsites.net",
        )
        model = model.bind_tools(tool_list, parallel_tool_calls=False)
        tools = ToolNode(tool_list, handle_tool_errors=(pydantic.ValidationError,))
        self.agent = create_react_agent(model, tools)

        self.timeout = timeout
        self.recursion_limit = recursion_limit

    async def _invoke_agent(self, agent, prompt):
        response = await asyncio.wait_for(
            agent.ainvoke(
                input={"messages": [{"role": "user", "content": prompt}]},
                config={"recursion_limit": self.recursion_limit},
            ),
            timeout=self.timeout
        )
        return response

    def run(self,
            task: str,
            task_kwargs: dict[str, str],
            initial_ids: set[str] = None,
            check_initial_ids: bool = False,
            ) -> tuple[Optional[str], str]:
        """
        Executes the agent's main task loop. It generates a response based on
        the task and its arguments, iterating over the conversation until a
        final answer is found.

        Args:
            task: The name or description of the task the agent should perform.
            task_kwargs: A dictionary of keyword arguments to further specify
                the task parameters.
            initial_ids: Initial KG identifiers to allow during hallucination detection
            check_initial_ids: Whether to check if the initial IDs are valid

        Returns:
            The final answer generated by the agent after iterating through the
                conversation and tool results.
        """
        if not self.graphdb.is_alive():
            raise ConnectionError("GraphDB is not running!")
        
        if check_initial_ids:
            for id in initial_ids:
                self.graphdb.check_id_in_graph(id)

        self.answer_store.initialize(initial_ids)
        self.graphdb.clear_session_ids()

        task_prompt = build_task_input(task, task_kwargs)
        response = asyncio.run(self._invoke_agent(self.agent, task_prompt))

        return self.answer_store.answer, response
